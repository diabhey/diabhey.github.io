[
    
        
            {
                "ref": "https://diabhey.github.io/2021/04/18/2021-04-18-local-k8s/",
                "title": "Multi-node K8s at home",
                "section": "post",
                "date" : "2021.04.18",
                "body": "Nowadays, there are many off-the-shelf solutions to get k8s up and running. Here are some of the Lightweight Kubernetes out there,\n kind microk8s k3s LKE (not free)  These k8s distribution have ample documentation and examples online that will easily help you set it up.\nLet\u0026rsquo;s do it the hard way In this blog post, I will guide the readers through a series of steps that I did to set up a multi-node K8s cluster at home.\nPre-requisites  System Requirements Hardware Requirements  Cluster node requirements is dependent on what you are going to run on k8s. I will assume you have met the minimum requirements to get started.\nMy Setup\n Control Plane: Intel NUC Worker Nodes: Two old laptops Both Control Plane and Woker Nodes are running Ubuntu 20.04-LTS  [To be continued]\n"
            }
        
    ,
        
            {
                "ref": "https://diabhey.github.io/2021/04/12/2021-04-12-remote-server-monitoring/",
                "title": "Remote Server Monitoring and Observability",
                "section": "post",
                "date" : "2021.04.12",
                "body": "The stations will be deployed across the globe and we need a way to effectively monitor and alert us in real-time. Thanks to Prometheus, all the heavy-lifting is done for us. In this post, I will run through a series of steps that is required to setup Prometheus on a linux server and then go ahead and setup Grafana Cloud as our observability platform through which can intuitively gain insights from our data sources across the globe.\nRequirements  Grafana Cloud Account Access to Linux Server(Node)  Set up Prometheus and Node Exporter Firstly, we will need to setup the node_exporter that is responsible for collecting the prometheus metrics and sending it to the grafana cloud.\n# Download the node_exporter wget https://github.com/prometheus/node_exporter/releases/download/v*/node_exporter-*.*-amd64.tar.gz # Extract and execute tar xvfz node_exporter-*.*-amd64.tar.gz cd node_exporter-*.*-amd64 ./node_exporter Secondly, install Prometheus on the node\n# Download prometheus wget https://github.com/prometheus/prometheus/releases/download/v*/prometheus-*.*-amd64.tar.gz # Extract  tar xvf prometheus-*.*-amd64.tar.gz cd prometheus-*.* Now we need to configure prometheus to publish the content to grafana cloud. For that, we need to create the prometheus.yml in the same directory as the prometheus binary with the following content,\nglobal: scrape_interval: 15s scrape_configs: - job_name: node static_configs: - targets: [\u0026#39;localhost:9100\u0026#39;] remote_write: - url: https://prometheus-us-central1.grafana.net/api/prom/push basic_auth: username: \u0026#34;your grafana username\u0026#34; password: \u0026#34;your Grafana API key\u0026#34; Save the file and we shall come back to it shortly. The grafana username and password need to be created in order to visualise the data on the grafana dashboard. Let\u0026rsquo;s login into grafana cloud portal and create a stack\nThe instance will be created shortly and an url will be generated through which we can access our grafana enterprise stack.\nCopy the Prometheus remote_write Configuration generated and add it to the prometheus.yml file we had created earlier. Save the file and exit.\nOpen a terminal and navigate to the prometheus and node_exporter directory and run the following,\n# Start prometheus ./prometheus --config.file=./prometheus.yml # Start node_exporter ./node_exporter Login into the https://\u0026lt;your stack\u0026gt;.grafana.net and select the data source as the prometheus instance that we had created earlier. This step is needed to visualise the data being published from the nodes. You can now create your own dashboard to monitor the metrics of your choice or import exisitng dashboards.\nFor this demo, I have imported the Node Exporter Quickstart Dashboard (id: 13978)\nThere you have it. On the next monitoring and observability series, I will explain how to configure our existing setup to also monitor the docker containers running on the nodes.\n"
            }
        
    ,
        
            {
                "ref": "https://diabhey.github.io/2021/02/14/2021-02-14-cloudception/",
                "title": "Cloudception",
                "section": "post",
                "date" : "2021.02.14",
                "body": "On Valentines day, I decided to go public about my love affair with the cloud. The more time I spend in the open source world, the stronger I feel to share my thoughts with all the CloudSurfers out there.\nI intend to use this space as a digital journal for all things cloud-native. The posts will be centered around the following topics but certainly not limited to\n  Cloud native tools and software\n  Hobby projects\n  Solutions to a technical problem\n  Cloud Native Conferences, Courses, Meetups\n  Let the journey begin\u0026hellip;\n"
            }
        
    
]