[
    
        
            {
                "ref": "https://diabhey.github.io/2021/04/18/2021-04-18-local-k8s/",
                "title": "Multi-node K8s at home",
                "section": "post",
                "date" : "2021.04.18",
                "body": "Nowadays, there are many off-the-shelf solutions to get k8s up and running. Here are some of the Lightweight Kubernetes out there,\n kind microk8s k3s LKE (not free)  These k8s distribution have ample documentation and examples online that will easily help you set it up.\nLet\u0026rsquo;s do it the hard way In this blog post, I will guide the readers through a series of steps that I did to set up a multi-node K8s cluster at home.\nPre-requisites  System Requirements Hardware Requirements  Cluster node requirements is dependent on what you are going to run on k8s. I will assume you have met the minimum requirements to get started.\nMy Setup\n Control Plane: Intel NUC Worker Nodes: Two old laptops Both Control Plane and Woker Nodes are running Ubuntu 20.04-LTS  [To be continued]\n"
            }
        
    ,
        
            {
                "ref": "https://diabhey.github.io/2021/04/12/2021-04-12-remote-server-monitoring/",
                "title": "Remote Server Monitoring and Observability",
                "section": "post",
                "date" : "2021.04.12",
                "body": "Here is a bit of a back story for the readers to understand the context better. We have our software(microservices) running on linux servers that will deployed across the globe. We also have our cloud platform through which we gain insights on our software[ more on that in a later blog] but that lacks the node and container metrics we need to monitor our servers. Due to the nature of the business, we have limted/restricted access to the client\u0026rsquo;s network. Based on the requirements and other factors we decided to side with open source tools and frameworks that will better integrate into our system.\nThanks to Prometheus, all the heavy-lifting is done for us. In this post, I will run through a series of steps that is required to setup Prometheus on a Linux server and then go ahead and setup Grafana Cloud as our observability platform through which can intuitively gain insights from our data sources across the globe.\nRequirements  Grafana Cloud Account Access to Linux Server(Node)  Set up Prometheus, Node Exporter and cAdvisor Firstly, we will need to setup the node_exporter that is responsible for collecting the prometheus metrics and sending it to the grafana cloud and then install prometheus on the node and even run them as a systemd service. One can find the instructions to set it up on this page. In case you want to run the services as docker containers, look no further. We will also be using cAdvisor(Container Advisor) that collects the container performance metrics.\nLet\u0026rsquo;s open a terminal and do the following shall we?,\n# Create a node_monitor directory on the node where you are running the monitoring services mkdir ~/node_monitor \u0026amp;\u0026amp; cd node_monitor # Create a docker-compose file to setup the services touch docker-compose.yml # Create a prometheus directory to store the config  mkdir prometheus \u0026amp;\u0026amp; cd prometheus # Create the config file touch prometheus.yml Configure Prometheus Now we need to configure prometheus to publish the metrics to grafana cloud. For that, we need to edit the contents of the prometheus.yml with the following,\nglobal: scrape_interval: 15s evaluation_interval: 15s scrape_configs: - job_name: node static_configs: - targets: [\u0026#39;localhost:9090\u0026#39;,\u0026#39;cadvisor:8080\u0026#39;,\u0026#39;node-exporter:9100\u0026#39;] remote_write: - url: https://prometheus-us-central1.grafana.net/api/prom/push basic_auth: username: \u0026#34;your grafana username\u0026#34; password: \u0026#34;your Grafana API key\u0026#34; Save the file and we shall come back to it shortly. The grafana username and password need to be created in order to visualize the data on the grafana dashboard.\n  Let\u0026rsquo;s login into grafana cloud portal and create a stack.\n  The instance will be created shortly and an url will be generated through which we can access our grafana enterprise stack.\n  Copy the Prometheus remote_write Configuration generated and add it to the prometheus.yml file we had created earlier. Save the file and exit.\n  Create the monitoring services â€‹Add the following contents to the docker-compose.yml\nversion: \u0026#39;3\u0026#39; services: prometheus: image: prom/prometheus:latest ports: - 9000:9090 volumes: - ./prometheus:/etc/prometheus - prometheus-data:/prometheus command: --web.enable-lifecycle --config.file=/etc/prometheus/prometheus.yml  expose: - 9090 ports: - 9090:9090 links: - cadvisor:cadvisor - node-exporter:node-exporter node-exporter: image: prom/node-exporter:latest container_name: monitoring_node_exporter restart: unless-stopped expose: - 9100 cadvisor: image: google/cadvisor:latest container_name: monitoring_cadvisor restart: unless-stopped volumes: - /:/rootfs:ro - /var/run:/var/run:rw - /sys:/sys:ro - /var/lib/docker/:/var/lib/docker:ro expose: - 8080 volumes: prometheus-data: Launch the services by running the following,\ndocker-compose -f docker-compose.yml up -d At this point, we have all the necessary services in place to start visualizing the data from the nodes.\nGrafana Cloud   Login into the https://\u0026lt;your stack\u0026gt;.grafana.net and select the data source as the prometheus instance that we had created earlier. This step is needed to visualise the data being published from the nodes. You can now create your own dashboard to monitor the metrics of your choice or import exisitng dashboards.\n  For this demo, I have imported the Node Exporter Quickstart Dashboard (id: 13978) and also the Docker and System Monitoring Dashboard(id: 893)\n  There you have it. Feel free to configure and play with these tools as they have much more to offer.\n"
            }
        
    ,
        
            {
                "ref": "https://diabhey.github.io/2021/02/14/2021-02-14-cloudception/",
                "title": "Cloudception",
                "section": "post",
                "date" : "2021.02.14",
                "body": "On Valentines day, I decided to go public about my love affair with the cloud. The more time I spend in the open source world, the stronger I feel to share my thoughts with all the CloudSurfers out there.\nI intend to use this space as a digital journal for all things cloud-native. The posts will be centered around the following topics but certainly not limited to\n  Cloud native tools and software\n  Hobby projects\n  Solutions to a technical problem\n  Cloud Native Conferences, Courses, Meetups\n  Let the journey begin\u0026hellip;\n"
            }
        
    
]